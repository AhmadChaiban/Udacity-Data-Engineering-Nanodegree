# Data Engineering Nanodegree
Learn to design data models, build data warehouses and data lakes, automate data pipelines, and work with massive datasets. At the end of the program, youâ€™ll combine your new skills by completing a capstone project.

5 months to complete 

## PREREQUISITE KNOWLEDGE
To be successful in this program, you should have intermediate Python and SQL skills.See detailed requirements.

## Data Modeling
Learn to create relational and NoSQL data models to fit the diverse needs of data consumers. Use ETL to build databases in PostgreSQL and Apache Cassandra.
- DATA MODELING WITH POSTGRES
- DATA MODELING WITH APACHE CASSANDRA

## Cloud Data Warehouses
Sharpen your data warehousing skills and deepen your understanding of data infrastructure. Create cloud-based data warehouses on Amazon Web Services (AWS).
- BUILD A CLOUD DATA WAREHOUSE

## Spark and Data Lakes
Understand the big data ecosystem and how to use Spark to work with massive datasets. Store big data in a data lake and query it with Spark.
- BUILD A DATA LAKE

## Data Pipelines with Airflow
Schedule, automate, and monitor data pipelines using Apache Airflow. Run data quality checks, track data lineage, and work with data pipelines in production.
- DATA PIPELINES WITH AIRFLOW

## Capstone Project
Combine what you've learned throughout the program to build your own data engineering portfolio project. This is currently still in progress. 
- DATA ENGINEERING CAPSTONE
